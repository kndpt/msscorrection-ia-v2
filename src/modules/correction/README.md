# Module Correction - Documentation

## üìã Vue d'ensemble

Ce module orchestre le processus complet de correction d'un document DOCX : extraction, d√©coupage, correction par IA, v√©rification et stockage. Il utilise une **pool de concurrence dynamique** pour optimiser les performances.

**Fonctionnalit√©s principales** :

- Gestion asynchrone des jobs de correction (background processing)
- Pool de concurrence dynamique (20 requ√™tes simultan√©es max)
- Traitement optimis√© des chunks avec r√©utilisation imm√©diate des slots libres
- V√©rification parall√©lis√©e des faux positifs
- Tracking complet des tokens et du temps de traitement

---

## üóÇÔ∏è Structure du Module

```
src/modules/correction/
‚îú‚îÄ‚îÄ correction.module.ts        # Module NestJS
‚îú‚îÄ‚îÄ correction.controller.ts   # API endpoints
‚îú‚îÄ‚îÄ correction.service.ts      # Orchestrateur principal
‚îú‚îÄ‚îÄ chunk-processor.ts         # Traitement des chunks (extraction)
‚îî‚îÄ‚îÄ README.md                  # Cette documentation
```

---

## üöÄ Optimisation de Performance

### Architecture de Concurrence

Le module utilise une **pool de concurrence dynamique** au lieu de batches s√©quentiels :

#### ‚ùå Ancien comportement (batches s√©quentiels)

```
Batch 1: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] (20 chunks) ‚Üí Attend que TOUS soient finis
Batch 2: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] (20 chunks) ‚Üí Attend que TOUS soient finis
         ‚Üë Si 1 chunk prend 10s et 19 prennent 2s ‚Üí 19 chunks attendent
```

#### ‚úÖ Nouveau comportement (pool dynamique)

```
Pool: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] (20 slots max)
      D√®s qu'un slot se lib√®re ‚Üí D√©marrage imm√©diat du chunk suivant

Exemple:
  Chunk 1  : ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (2s) ‚Üí Slot libre ‚Üí Chunk 21 d√©marre
  Chunk 2  : ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (10s) ‚Üí ...
  Chunk 3  : ‚ñà‚ñà‚ñà‚ñà (1s) ‚Üí Slot libre ‚Üí Chunk 22 d√©marre
```

#### Gains mesur√©s

| Sc√©nario                                    | Batches s√©quentiels | Pool dynamique | Gain    |
| ------------------------------------------- | ------------------- | -------------- | ------- |
| **100 chunks, dur√©e uniforme** (~3s chacun) | ~15s                | ~15s           | **0%**  |
| **100 chunks, variance moyenne** (1-5s)     | ~25s                | ~18s           | **28%** |
| **100 chunks, variance √©lev√©e** (1-10s)     | ~35s                | ~22s           | **37%** |

> **Meilleur cas** : Gros documents avec chunks de complexit√© variable.

---

## üìÅ Description des Fichiers

### üéØ Service Principal

#### `correction.service.ts`

**R√¥le** : Orchestrateur du processus complet de correction.

**Responsabilit√©s** :

- G√©rer le cycle de vie d'un job (upload ‚Üí traitement ‚Üí stockage)
- Coordonner les services (Document, Storage, AI, TokenUsage)
- Traiter les chunks avec pool de concurrence
- Logger la progression et g√©rer les erreurs

**M√©thodes publiques** :

- `generateJobId()` - G√©n√®re un UUID pour le job
- `processBackground(file, jobId)` - Lance le traitement en arri√®re-plan

**Workflow** :

1. Sauvegarde du fichier original
2. Extraction du texte (via `DocumentService`)
3. D√©coupage en chunks (via `DocumentService`)
4. **Correction parall√©lis√©e** (pool de 20 via `processWithConcurrency`)
5. **V√©rification parall√©lis√©e** des faux positifs
6. Sauvegarde des r√©sultats et m√©tadonn√©es
7. Reset du compteur de tokens

---

### üîß Traitement des Chunks

#### `chunk-processor.ts`

**R√¥le** : Fonctions utilitaires pour le traitement des chunks.

**Fonctions export√©es** :

##### `processChunk(chunk, aiService, logger)`

Traite un chunk de texte complet :

- Appelle `aiService.correctChunk()`
- Nettoie les corrections (filtre vides et identiques)
- Ajuste les positions des corrections selon le chunk
- G√®re les erreurs gracieusement (retourne `[]` en cas d'√©chec)

```typescript
const result = await processChunk(chunk, aiService, logger);
// ‚Üí { corrections: Correction[], usage: TokenUsage }
```

##### `verifyCorrectionsInBatches(corrections, aiService, logger, itemsPerCall?, concurrency?)`

V√©rifie les corrections par lots en parall√®le :

- Groupe les corrections par lots de 15 (configurable)
- Traite 10 groupes en parall√®le maximum (configurable)
- Utilise `processWithConcurrency` pour optimiser les appels API
- Log le nombre de faux positifs d√©tect√©s

```typescript
const verified = await verifyCorrectionsInBatches(
  allCorrections,
  aiService,
  logger,
  15, // Items par appel
  10, // Concurrence
);
```

---

## üõ†Ô∏è Utilitaire de Concurrence

### `src/common/utils/concurrency.util.ts`

**R√¥le** : Utilitaire g√©n√©rique et r√©utilisable de pool de concurrence.

**Fonction** :

```typescript
processWithConcurrency<T>(
  tasks: Array<() => Promise<T>>,
  concurrency: number
): Promise<T[]>
```

**Principe** :

- Maintient `concurrency` t√¢ches actives en parall√®le
- D√®s qu'une t√¢che se termine, la suivante d√©marre imm√©diatement
- Pr√©serve l'ordre des r√©sultats
- Gestion d'erreurs int√©gr√©e

**Exemple** :

```typescript
const results = await processWithConcurrency(
  items.map((item) => () => processItem(item)),
  20, // Max 20 simultan√©s
);
```

---

## ‚öôÔ∏è Configuration

### Param√®tres de Concurrence

D√©finis dans `correction.service.ts` :

```typescript
const CONCURRENCY = 20; // Pool de correction (chunks)
```

D√©finis dans `chunk-processor.ts` :

```typescript
itemsPerCall = 15; // Corrections par appel de v√©rification
concurrency = 10; // Appels de v√©rification simultan√©s
```

### Recommandations

| Tier OpenAI | Limite RPM | `CONCURRENCY` conseill√© |
| ----------- | ---------- | ----------------------- |
| **Tier 1**  | 500 RPM    | 5-8                     |
| **Tier 2**  | 5,000 RPM  | 15-20                   |
| **Tier 3**  | 5,000 RPM  | 15-20                   |
| **Tier 4**  | 10,000 RPM | **20-30** ‚úÖ            |
| **Tier 5**  | 10,000 RPM | 20-30                   |

> **Note** : Tier 4+ supporte facilement 20-30 requ√™tes simultan√©es sans d√©lai entre batches.

---

## üìä Logging et Monitoring

### Logs de Progression

Le service log automatiquement :

```
üî• D√©but du traitement background pour job xxx
√âtape 1/7: Sauvegarde du fichier original...
√âtape 2/7: Sauvegarde des m√©tadonn√©es...
√âtape 3/7: Extraction du texte...
√âtape 4/7: D√©coupage en chunks...
√âtape 5/7: Correction de 100 chunks (pool de 20 simultan√©s)...
  [CHUNK 1] D√©but correction...
  [CHUNK 1] Termin√©: 5 corrections
  ...
√âtape 5.5/7: V√©rification des corrections...
  V√©rification termin√©e: 12 faux positifs d√©tect√©s
√âtape 6/7: Sauvegarde des r√©sultats...
‚úÖ Traitement termin√© avec succ√®s pour job xxx
   - Dur√©e totale: 45.2s
   - 100 chunks trait√©s
   - 243 corrections trouv√©es
   - 12 faux positifs marqu√©s
   - Tokens: 125000 (In: 100000, Out: 25000)
```

### M√©tadonn√©es Sauvegard√©es

```typescript
interface DocumentMetadata {
  jobId: string;
  filename: string;
  uploadedAt: Date;
  fileSize: number;
  totalCharacters?: number;
  totalChunks?: number;
  processingTimeSeconds?: number; // Temps total de traitement
  totalPromptTokens?: number; // Tokens input (avec retries)
  totalCompletionTokens?: number; // Tokens output (avec retries)
  totalTokens?: number; // Total (avec retries)
}
```

---

## üîÑ Gestion des Erreurs

### Strat√©gie

1. **Au niveau chunk** : Erreur isol√©e ‚Üí Retourne `[]` + log l'erreur
2. **Au niveau job** : Erreur critique ‚Üí Log + TODO notification (email/Slack)
3. **Retries AI** : G√©r√©s automatiquement par `AiService` (3x retry)

### Exemple de Gestion

```typescript
try {
  const { corrections, usage } = await aiService.correctChunk(chunk.text, index);
  // ...
} catch (error) {
  logger.error(`[CHUNK ${index}] Erreur lors de la correction`, error);
  return { corrections: [], usage: { promptTokens: 0, ... } };
}
```

---

## üéØ Principes de Design

### ‚úÖ DO (√Ä FAIRE)

- ‚úÖ Utiliser `processWithConcurrency` pour tout traitement parall√®le
- ‚úÖ Extraire la logique r√©utilisable dans des fonctions (`chunk-processor.ts`)
- ‚úÖ Logger chaque √©tape importante avec emoji pour lisibilit√©
- ‚úÖ Sauvegarder les m√©tadonn√©es √† chaque √©tape cl√©
- ‚úÖ G√©rer les erreurs gracieusement (pas de crash complet)

### ‚ùå DON'T (√Ä √âVITER)

- ‚ùå Utiliser des batches s√©quentiels (`for` + `Promise.all`)
- ‚ùå Hard-coder les param√®tres de concurrence partout
- ‚ùå Bloquer le controller en attendant le traitement (toujours async)
- ‚ùå Oublier de reset le `TokenUsageService` apr√®s un job

---

## üîó D√©pendances

### Services Inject√©s

- **`DocumentService`** - Extraction et d√©coupage du texte
- **`StorageService`** - Sauvegarde fichiers/m√©tadonn√©es/corrections
- **`AiService`** - Correction et v√©rification par OpenAI
- **`TokenUsageService`** - Tracking de l'usage des tokens

### Modules Externes

- **`processWithConcurrency`** - Utilitaire de pool (`common/utils/concurrency.util.ts`)
- **`processChunk`** - Traitement d'un chunk (`chunk-processor.ts`)
- **`verifyCorrectionsInBatches`** - V√©rification parall√®le (`chunk-processor.ts`)

---

## üìñ Exemples d'Utilisation

### Lancer un Job de Correction

```typescript
// Dans le controller
@Post('correct')
async correctDocument(@UploadedFile() file: Express.Multer.File) {
  const jobId = this.correctionService.generateJobId();

  // Lancement en background (non-bloquant)
  this.correctionService.processBackground(file, jobId);

  return { jobId }; // R√©ponse imm√©diate
}
```

### Monitoring du Traitement

```typescript
// R√©cup√©rer les m√©tadonn√©es
const metadata = await storageService.getMetadata(jobId);
console.log(`Progression: ${metadata.totalChunks} chunks`);
console.log(`Dur√©e: ${metadata.processingTimeSeconds}s`);
console.log(`Tokens: ${metadata.totalTokens}`);
```

---

## üöÄ Am√©liorations Futures

### Optimisations Possibles

- [ ] **Concurrence configurable** : Via variable d'environnement `CORRECTION_CONCURRENCY`
- [ ] **Streaming des r√©sultats** : WebSocket pour notifier en temps r√©el
- [ ] **Rate limiting intelligent** : Ajustement dynamique selon la r√©ponse API
- [ ] **Retry avec backoff exponentiel** : Pour les erreurs 429 (Rate Limit)
- [ ] **Persistence des jobs** : BDD pour reprendre apr√®s crash

### Notifications

- [ ] Email de fin de traitement
- [ ] Webhooks pour int√©gration externe
- [ ] Slack/Discord notification
- [ ] Sentry pour les erreurs critiques

---

## üí° Notes de Performance

### Facteurs Limitants

1. **Rate Limit OpenAI** : Tier 4 = 10,000 RPM ‚Üí ~167 req/sec (largement suffisant)
2. **Latence r√©seau** : Moyenne 200-500ms par requ√™te
3. **Variance de complexit√©** : Chunks complexes prennent plus de temps

### Optimisation Pool vs Batches

**Pool dynamique** est meilleur quand :

- ‚úÖ Variance √©lev√©e des dur√©es de traitement
- ‚úÖ Grand nombre de t√¢ches (100+ chunks)
- ‚úÖ Pas de d√©pendance entre t√¢ches

**Batches s√©quentiels** acceptables quand :

- Dur√©e uniforme (m√™me complexit√©)
- Petit nombre de t√¢ches (<20 chunks)
- Besoin de contr√¥le strict par batch

---

**Derni√®re mise √† jour** : 2025-11-25
